# LLM Fundamentals

> **Status:** Stub - Implementation coming soon

## Overview

Understanding large language models (GPT, BERT, LLaMA, etc.).

## Topics

### Pretraining Objectives
- Masked Language Modeling (BERT)
- Causal Language Modeling (GPT)
- Prefix Language Modeling (T5)

### Scaling Laws
- Model size
- Dataset size
- Compute budget

### Fine-tuning
- Full fine-tuning
- LoRA (Low-Rank Adaptation)
- Prompt tuning

### Inference
- Autoregressive generation
- Sampling strategies
- KV-cache optimization

## Contributing

See [CONTRIBUTING.md](../../../CONTRIBUTING.md).
