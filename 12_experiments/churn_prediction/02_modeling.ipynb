{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Churn Prediction: Modeling & Evaluation\n",
                "\n",
                "Here we build predictive models, focusing on **metric selection**, **threshold tuning**, and **business impact**.\n",
                "\n",
                "## Goals\n",
                "1. Preprocess data without leakage\n",
                "2. Compare baseline vs. advanced models\n",
                "3. Optimize threshold for business value\n",
                "4. Interpret feature importance"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import pandas as pd\n",
                "import numpy as np\n",
                "import matplotlib.pyplot as plt\n",
                "import seaborn as sns\n",
                "\n",
                "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
                "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
                "from sklearn.compose import ColumnTransformer\n",
                "from sklearn.pipeline import Pipeline\n",
                "from sklearn.linear_model import LogisticRegression\n",
                "from sklearn.ensemble import RandomForestClassifier\n",
                "from sklearn.metrics import classification_report, roc_auc_score, confusion_matrix, precision_recall_curve\n",
                "\n",
                "df = pd.read_csv('data/telco_churn.csv')\n",
                "\n",
                "# Minimal cleaning (same as EDA)\n",
                "df['TotalCharges'] = pd.to_numeric(df['TotalCharges'], errors='coerce').fillna(0)\n",
                "df['Churn'] = (df['Churn'] == 'Yes').astype(int)\n",
                "df.drop('customerID', axis=1, inplace=True)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Train-Test Split (The First Line of Defense)\n",
                "\n",
                "> **DECISION CHECKPOINT 1**: Stratified Split\n",
                "> Since churn is imbalanced (26%), a random split might result in one set having much less churn. \n",
                "> **Action**: Use `stratify=y` to preserve class distribution."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "X = df.drop('Churn', axis=1)\n",
                "y = df['Churn']\n",
                "\n",
                "X_train, X_test, y_train, y_test = train_test_split(\n",
                "    X, y, test_size=0.2, random_state=42, stratify=y\n",
                ")\n",
                "\n",
                "print(f\"Train churn rate: {y_train.mean():.1%}\")\n",
                "print(f\"Test churn rate: {y_test.mean():.1%}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Preprocessing Pipeline (Preventing Leakage)\n",
                "\n",
                "We must define categorical and numerical columns explicitly."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "num_cols = ['tenure', 'MonthlyCharges', 'TotalCharges']\n",
                "cat_cols = X.select_dtypes(include=['object']).columns\n",
                "\n",
                "preprocessor = ColumnTransformer([\n",
                "    ('num', StandardScaler(), num_cols),\n",
                "    ('cat', OneHotEncoder(drop='first', handle_unknown='ignore'), cat_cols)\n",
                "])\n",
                "\n",
                "# Baseline Model: Logistic Regression\n",
                "lr_model = Pipeline([\n",
                "    ('preprocessor', preprocessor),\n",
                "    ('classifier', LogisticRegression(max_iter=1000))\n",
                "])\n",
                "\n",
                "lr_model.fit(X_train, y_train)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Advanced Model: Random Forest\n",
                "\n",
                "Does capturing non-linear interactions (like Tenure Ã— Contract) help?"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "rf_model = Pipeline([\n",
                "    ('preprocessor', preprocessor),\n",
                "    ('classifier', RandomForestClassifier(n_estimators=100, max_depth=10, random_state=42))\n",
                "])\n",
                "\n",
                "rf_model.fit(X_train, y_train)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Evaluation & Metric Selection\n",
                "\n",
                "> **DECISION CHECKPOINT 2**: Which metric matters?\n",
                ">\n",
                "> - **Accuracy**: Misleading (null accuracy is 73%).\n",
                "> - **Recall**: Critical. We want to find churners to save them.\n",
                "> - **Precision**: Important. Interventions cost money.\n",
                ">\n",
                "> **Action**: Compare AUC-ROC and look at Recall-Precision tradeoff."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def evaluate_model(model, name):\n",
                "    y_pred = model.predict(X_test)\n",
                "    y_prob = model.predict_proba(X_test)[:, 1]\n",
                "    \n",
                "    print(f\"--- {name} ---\")\n",
                "    print(classification_report(y_test, y_pred))\n",
                "    print(f\"ROC-AUC: {roc_auc_score(y_test, y_prob):.3f}\")\n",
                "\n",
                "evaluate_model(lr_model, \"Logistic Regression\")\n",
                "evaluate_model(rf_model, \"Random Forest\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. Threshold Tuning for Business Impact\n",
                "\n",
                "Default threshold is 0.5. But is that optimal?\n",
                "\n",
                "**Business Case**:\n",
                "- Customer Lifetime Value (LTV): $2000\n",
                "- Retention Offer Cost: $100\n",
                "- Discount Acceptance Rate: 50%\n",
                "\n",
                "If we catch a churner, we save $2000 * 0.5 = $1000.\n",
                "Cost = $100.\n",
                "Benefit/Cost ratio = 10:1.\n",
                "\n",
                "This means we should aggressively predict churn!"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "y_scores = rf_model.predict_proba(X_test)[:, 1]\n",
                "\n",
                "p, r, thresholds = precision_recall_curve(y_test, y_scores)\n",
                "\n",
                "plt.figure(figsize=(8, 6))\n",
                "plt.plot(thresholds, p[:-1], label='Precision')\n",
                "plt.plot(thresholds, r[:-1], label='Recall')\n",
                "plt.xlabel('Threshold')\n",
                "plt.legend()\n",
                "plt.title('Precision-Recall Tradeoff')\n",
                "plt.axvline(x=0.3, color='black', linestyle='--', label='Proposed Threshold')\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "> **DECISION CHECKPOINT 3**: Optimal Threshold\n",
                ">\n",
                "> By lowering threshold to **0.3**, we increase Recall from ~50% to ~80%, catching far more churners.\n",
    "> Precision drops, but since the benefit of saving a customer (\$1000) > cost of misfire (\$100), this is profitable."
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.5"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}