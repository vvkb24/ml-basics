# Papers

## Foundational Papers

### Neural Networks
- **Perceptron** - Rosenblatt (1958)
- **Backpropagation** - Rumelhart, Hinton, Williams (1986)

### Deep Learning
- **ImageNet Classification with Deep CNNs** (AlexNet) - Krizhevsky et al. (2012)
- **Very Deep Convolutional Networks** (VGG) - Simonyan & Zisserman (2014)
- **Deep Residual Learning** (ResNet) - He et al. (2015)

### Regularization
- **Dropout** - Srivastava et al. (2014)
- **Batch Normalization** - Ioffe & Szegedy (2015)

### Optimization
- **Adam Optimizer** - Kingma & Ba (2014)
- **Learning Rate Schedules** - Smith (2017)

## Sequence Models
- **LSTM** - Hochreiter & Schmidhuber (1997)
- **GRU** - Cho et al. (2014)
- **Sequence to Sequence** - Sutskever et al. (2014)

## Attention & Transformers
- **Attention Is All You Need** - Vaswani et al. (2017)
- **BERT** - Devlin et al. (2018)
- **GPT-2/3** - Radford et al. (2019/2020)

## Reading Lists

### Must-Read for Beginners
1. AlexNet paper
2. Dropout paper
3. Adam paper
4. Attention Is All You Need

### For Deep Understanding
1. Original backprop paper
2. Batch Normalization
3. ResNet
4. Transformer paper with annotations
