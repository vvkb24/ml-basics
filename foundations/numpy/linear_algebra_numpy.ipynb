{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Linear Algebra with NumPy\n",
                "\n",
                "Essential linear algebra operations for machine learning."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import numpy as np\n",
                "np.set_printoptions(precision=3, suppress=True)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Dot Product and Matrix Multiplication"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Dot product of vectors\n",
                "a = np.array([1, 2, 3])\n",
                "b = np.array([4, 5, 6])\n",
                "\n",
                "dot = np.dot(a, b)  # or a @ b\n",
                "print(f\"a · b = {dot}\")\n",
                "print(f\"Manual: 1*4 + 2*5 + 3*6 = {1*4 + 2*5 + 3*6}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Matrix multiplication\n",
                "A = np.array([[1, 2], [3, 4]])\n",
                "B = np.array([[5, 6], [7, 8]])\n",
                "\n",
                "C = A @ B  # or np.matmul(A, B)\n",
                "print(f\"A @ B =\\n{C}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Matrix-vector multiplication\n",
                "W = np.array([[1, 2, 3], [4, 5, 6]])  # 2x3\n",
                "x = np.array([1, 0, 1])  # 3-vector\n",
                "\n",
                "result = W @ x  # (2x3) @ (3,) = (2,)\n",
                "print(f\"Wx = {result}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Transpose"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "A = np.array([[1, 2, 3], [4, 5, 6]])\n",
                "print(f\"A:\\n{A}\\n\")\n",
                "print(f\"A^T:\\n{A.T}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# XᵀX is common in linear regression\n",
                "X = np.array([[1, 2], [3, 4], [5, 6]])\n",
                "XtX = X.T @ X\n",
                "print(f\"X (3x2):\\n{X}\\n\")\n",
                "print(f\"XᵀX (2x2):\\n{XtX}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Norms"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "v = np.array([3, 4])\n",
                "\n",
                "# L2 norm (Euclidean)\n",
                "l2 = np.linalg.norm(v)\n",
                "print(f\"||v||_2 = {l2}\")\n",
                "\n",
                "# L1 norm (Manhattan)\n",
                "l1 = np.linalg.norm(v, ord=1)\n",
                "print(f\"||v||_1 = {l1}\")\n",
                "\n",
                "# Infinity norm\n",
                "linf = np.linalg.norm(v, ord=np.inf)\n",
                "print(f\"||v||_∞ = {linf}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Frobenius norm for matrices\n",
                "A = np.array([[1, 2], [3, 4]])\n",
                "frob = np.linalg.norm(A, 'fro')\n",
                "print(f\"||A||_F = {frob}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Inverse and Pseudo-Inverse"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Matrix inverse\n",
                "A = np.array([[4, 7], [2, 6]])\n",
                "A_inv = np.linalg.inv(A)\n",
                "\n",
                "print(f\"A:\\n{A}\\n\")\n",
                "print(f\"A⁻¹:\\n{A_inv}\\n\")\n",
                "print(f\"A @ A⁻¹:\\n{A @ A_inv}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Moore-Penrose pseudo-inverse (works for non-square matrices)\n",
                "X = np.array([[1, 2], [3, 4], [5, 6]])\n",
                "X_pinv = np.linalg.pinv(X)\n",
                "\n",
                "print(f\"X (3x2):\\n{X}\\n\")\n",
                "print(f\"X⁺ (2x3):\\n{X_pinv}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# For XᵀX (normal equation)\n",
                "XtX = X.T @ X\n",
                "XtX_inv = np.linalg.inv(XtX)\n",
                "print(f\"(XᵀX)⁻¹:\\n{XtX_inv}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. Determinant and Trace"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "A = np.array([[1, 2], [3, 4]])\n",
                "\n",
                "det = np.linalg.det(A)\n",
                "trace = np.trace(A)\n",
                "\n",
                "print(f\"det(A) = {det}\")\n",
                "print(f\"trace(A) = {trace}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 6. Eigendecomposition"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Symmetric matrix (guaranteed real eigenvalues)\n",
                "A = np.array([[4, 2], [2, 3]])\n",
                "\n",
                "eigenvalues, eigenvectors = np.linalg.eig(A)\n",
                "\n",
                "print(f\"A:\\n{A}\\n\")\n",
                "print(f\"Eigenvalues: {eigenvalues}\")\n",
                "print(f\"Eigenvectors:\\n{eigenvectors}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Verify: Av = λv\n",
                "v = eigenvectors[:, 0]\n",
                "lam = eigenvalues[0]\n",
                "\n",
                "print(f\"Av = {A @ v}\")\n",
                "print(f\"λv = {lam * v}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# For symmetric matrices, use eigh (more stable)\n",
                "eigenvalues, eigenvectors = np.linalg.eigh(A)\n",
                "print(f\"Eigenvalues (sorted): {eigenvalues}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 7. Singular Value Decomposition (SVD)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# A = UΣVᵀ\n",
                "A = np.array([[1, 2], [3, 4], [5, 6]])\n",
                "\n",
                "U, S, Vt = np.linalg.svd(A)\n",
                "\n",
                "print(f\"A (3x2):\\n{A}\\n\")\n",
                "print(f\"U (3x3):\\n{U}\\n\")\n",
                "print(f\"S (singular values): {S}\\n\")\n",
                "print(f\"Vᵀ (2x2):\\n{Vt}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Reconstruct A\n",
                "Sigma = np.zeros((3, 2))\n",
                "Sigma[:2, :2] = np.diag(S)\n",
                "\n",
                "A_reconstructed = U @ Sigma @ Vt\n",
                "print(f\"Reconstructed:\\n{A_reconstructed}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Low-rank approximation (PCA basis)\n",
                "# Keep only first k singular values\n",
                "k = 1\n",
                "A_approx = U[:, :k] @ np.diag(S[:k]) @ Vt[:k, :]\n",
                "print(f\"Rank-{k} approximation:\\n{A_approx}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 8. Solving Linear Systems"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Solve Ax = b\n",
                "A = np.array([[3, 1], [1, 2]])\n",
                "b = np.array([9, 8])\n",
                "\n",
                "x = np.linalg.solve(A, b)\n",
                "print(f\"Solution x: {x}\")\n",
                "print(f\"Verify Ax: {A @ x}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Least squares (overdetermined system)\n",
                "# Minimize ||Ax - b||²\n",
                "A = np.array([[1, 1], [1, 2], [1, 3]])\n",
                "b = np.array([1, 2, 2])\n",
                "\n",
                "x, residuals, rank, s = np.linalg.lstsq(A, b, rcond=None)\n",
                "print(f\"Least squares solution: {x}\")\n",
                "print(f\"Residuals: {residuals}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 9. QR Decomposition"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# A = QR where Q is orthogonal, R is upper triangular\n",
                "A = np.array([[1, 2], [3, 4], [5, 6]])\n",
                "\n",
                "Q, R = np.linalg.qr(A)\n",
                "\n",
                "print(f\"A (3x2):\\n{A}\\n\")\n",
                "print(f\"Q (orthogonal):\\n{Q}\\n\")\n",
                "print(f\"R (upper triangular):\\n{R}\\n\")\n",
                "print(f\"QᵀQ (should be I):\\n{Q.T @ Q}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Verify reconstruction\n",
                "print(f\"Q @ R:\\n{Q @ R}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 10. Cholesky Decomposition"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# For positive definite matrices: A = LLᵀ\n",
                "# L is lower triangular\n",
                "A = np.array([[4, 2, 2], [2, 5, 1], [2, 1, 6]])  # Positive definite\n",
                "\n",
                "L = np.linalg.cholesky(A)\n",
                "\n",
                "print(f\"A:\\n{A}\\n\")\n",
                "print(f\"L (lower triangular):\\n{L}\\n\")\n",
                "print(f\"L @ Lᵀ:\\n{L @ L.T}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Use Cholesky for efficient solving Ax = b\n",
                "b = np.array([1, 2, 3])\n",
                "\n",
                "# Solve Ly = b (forward substitution)\n",
                "y = np.linalg.solve(L, b)\n",
                "# Solve Lᵀx = y (backward substitution)\n",
                "x = np.linalg.solve(L.T, y)\n",
                "\n",
                "print(f\"Solution x: {x}\")\n",
                "print(f\"Verify Ax: {A @ x}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 11. Condition Number and Numerical Stability"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Condition number: sensitivity to perturbations\n",
                "A = np.array([[1, 2], [3, 4]])\n",
                "cond = np.linalg.cond(A)\n",
                "print(f\"Condition number of A: {cond}\")\n",
                "\n",
                "# Ill-conditioned matrix (near singular)\n",
                "B = np.array([[1, 1], [1, 1.0001]])\n",
                "cond_B = np.linalg.cond(B)\n",
                "print(f\"Condition number of B (ill-conditioned): {cond_B}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Matrix rank\n",
                "A = np.array([[1, 2, 3], [2, 4, 6], [1, 1, 1]])\n",
                "rank = np.linalg.matrix_rank(A)\n",
                "print(f\"Rank of A: {rank}\")\n",
                "print(f\"(Row 2 is 2x Row 1, so rank < 3)\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 12. Outer Product and Kronecker Product"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Outer product: u ⊗ v = uvᵀ\n",
                "u = np.array([1, 2, 3])\n",
                "v = np.array([4, 5])\n",
                "\n",
                "outer = np.outer(u, v)\n",
                "print(f\"u: {u}\")\n",
                "print(f\"v: {v}\")\n",
                "print(f\"Outer product:\\n{outer}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Kronecker product (tensor product)\n",
                "A = np.array([[1, 2], [3, 4]])\n",
                "B = np.array([[0, 5], [6, 7]])\n",
                "\n",
                "kron = np.kron(A, B)\n",
                "print(f\"Kronecker product:\\n{kron}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 13. Matrix Exponential and Power"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from scipy.linalg import expm\n",
                "\n",
                "# Matrix exponential: e^A\n",
                "A = np.array([[0, 1], [-1, 0]])  # Rotation generator\n",
                "exp_A = expm(A)\n",
                "print(f\"e^A:\\n{exp_A}\")\n",
                "print(f\"(This is a rotation matrix)\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Matrix power\n",
                "A = np.array([[1, 1], [1, 0]])  # Fibonacci matrix\n",
                "A_power = np.linalg.matrix_power(A, 10)\n",
                "print(f\"A^10:\\n{A_power}\")\n",
                "print(f\"(Contains Fibonacci numbers!)\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 14. Gram-Schmidt Orthogonalization"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def gram_schmidt(A):\n",
                "    \"\"\"Orthogonalize columns of A using Gram-Schmidt.\"\"\"\n",
                "    Q = np.zeros_like(A, dtype=float)\n",
                "    for i in range(A.shape[1]):\n",
                "        q = A[:, i].astype(float)\n",
                "        for j in range(i):\n",
                "            q = q - np.dot(Q[:, j], A[:, i]) * Q[:, j]\n",
                "        Q[:, i] = q / np.linalg.norm(q)\n",
                "    return Q\n",
                "\n",
                "A = np.array([[1, 1, 0], [1, 0, 1], [0, 1, 1]])\n",
                "Q = gram_schmidt(A)\n",
                "\n",
                "print(f\"Original A:\\n{A}\\n\")\n",
                "print(f\"Orthonormal Q:\\n{Q}\\n\")\n",
                "print(f\"QᵀQ (should be I):\\n{Q.T @ Q}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 15. Projections"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Project vector onto another vector\n",
                "def project_vector(v, u):\n",
                "    \"\"\"Project v onto u.\"\"\"\n",
                "    return (np.dot(v, u) / np.dot(u, u)) * u\n",
                "\n",
                "v = np.array([3, 4])\n",
                "u = np.array([1, 0])\n",
                "\n",
                "proj = project_vector(v, u)\n",
                "print(f\"v: {v}\")\n",
                "print(f\"u: {u}\")\n",
                "print(f\"Projection of v onto u: {proj}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Projection matrix: P = A(AᵀA)⁻¹Aᵀ\n",
                "A = np.array([[1, 0], [0, 1], [0, 0]])\n",
                "P = A @ np.linalg.inv(A.T @ A) @ A.T\n",
                "\n",
                "print(f\"Projection matrix:\\n{P}\\n\")\n",
                "\n",
                "# Verify: P² = P (idempotent)\n",
                "print(f\"P² = P: {np.allclose(P @ P, P)}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 16. ML Applications"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Linear Regression via Normal Equation\n",
                "# θ = (XᵀX)⁻¹Xᵀy\n",
                "\n",
                "# Generate data\n",
                "np.random.seed(42)\n",
                "X = np.random.randn(100, 3)\n",
                "true_weights = np.array([2, -1, 0.5])\n",
                "y = X @ true_weights + np.random.randn(100) * 0.1\n",
                "\n",
                "# Add bias column\n",
                "X_b = np.c_[np.ones(100), X]\n",
                "\n",
                "# Normal equation\n",
                "theta = np.linalg.inv(X_b.T @ X_b) @ X_b.T @ y\n",
                "print(f\"Learned weights: {theta[1:]}\")\n",
                "print(f\"True weights: {true_weights}\")\n",
                "print(f\"Bias: {theta[0]:.4f}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# PCA using eigendecomposition\n",
                "X = np.random.randn(100, 5)\n",
                "\n",
                "# Center data\n",
                "X_centered = X - X.mean(axis=0)\n",
                "\n",
                "# Covariance matrix\n",
                "cov = X_centered.T @ X_centered / (len(X) - 1)\n",
                "\n",
                "# Eigendecomposition\n",
                "eigenvalues, eigenvectors = np.linalg.eigh(cov)\n",
                "\n",
                "# Sort by eigenvalue (descending)\n",
                "idx = eigenvalues.argsort()[::-1]\n",
                "eigenvalues = eigenvalues[idx]\n",
                "eigenvectors = eigenvectors[:, idx]\n",
                "\n",
                "# Explained variance ratio\n",
                "explained_var_ratio = eigenvalues / eigenvalues.sum()\n",
                "print(f\"Explained variance ratio: {explained_var_ratio}\")\n",
                "print(f\"Cumulative: {np.cumsum(explained_var_ratio)}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Whitening (decorrelation + unit variance)\n",
                "def whiten(X):\n",
                "    \"\"\"Whiten data using eigendecomposition.\"\"\"\n",
                "    X_centered = X - X.mean(axis=0)\n",
                "    cov = X_centered.T @ X_centered / len(X)\n",
                "    eigenvalues, eigenvectors = np.linalg.eigh(cov)\n",
                "    \n",
                "    # Whitening matrix: W = V @ D^(-1/2)\n",
                "    D_inv_sqrt = np.diag(1.0 / np.sqrt(eigenvalues + 1e-8))\n",
                "    W = eigenvectors @ D_inv_sqrt\n",
                "    \n",
                "    return X_centered @ W\n",
                "\n",
                "X_whitened = whiten(X)\n",
                "print(f\"Original covariance diagonal: {np.diag(np.cov(X.T))}\")\n",
                "print(f\"Whitened covariance diagonal: {np.diag(np.cov(X_whitened.T))}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Mahalanobis distance\n",
                "def mahalanobis_distance(x, mean, cov):\n",
                "    \"\"\"Compute Mahalanobis distance.\"\"\"\n",
                "    diff = x - mean\n",
                "    cov_inv = np.linalg.inv(cov)\n",
                "    return np.sqrt(diff.T @ cov_inv @ diff)\n",
                "\n",
                "# Example: detect outliers\n",
                "np.random.seed(42)\n",
                "data = np.random.randn(100, 2)\n",
                "mean = data.mean(axis=0)\n",
                "cov = np.cov(data.T)\n",
                "\n",
                "# Test point\n",
                "normal_point = np.array([0.5, 0.5])\n",
                "outlier = np.array([5, 5])\n",
                "\n",
                "print(f\"Mahalanobis distance (normal): {mahalanobis_distance(normal_point, mean, cov):.2f}\")\n",
                "print(f\"Mahalanobis distance (outlier): {mahalanobis_distance(outlier, mean, cov):.2f}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 17. Exercises"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Exercise 1: Implement cosine similarity\n",
                "def cosine_similarity(u, v):\n",
                "    \"\"\"Compute cosine similarity between two vectors.\"\"\"\n",
                "    return np.dot(u, v) / (np.linalg.norm(u) * np.linalg.norm(v))\n",
                "\n",
                "a = np.array([1, 0])\n",
                "b = np.array([1, 1])\n",
                "print(f\"Cosine similarity: {cosine_similarity(a, b):.4f}\")\n",
                "print(f\"Expected (cos 45°): {np.cos(np.pi/4):.4f}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Exercise 2: Check if matrix is positive definite\n",
                "def is_positive_definite(A):\n",
                "    \"\"\"Check if matrix is positive definite.\"\"\"\n",
                "    eigenvalues = np.linalg.eigvals(A)\n",
                "    return np.all(eigenvalues > 0)\n",
                "\n",
                "A = np.array([[2, -1], [-1, 2]])\n",
                "B = np.array([[1, 2], [2, 1]])\n",
                "\n",
                "print(f\"A is PD: {is_positive_definite(A)}\")\n",
                "print(f\"B is PD: {is_positive_definite(B)}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Exercise 3: Implement power iteration for largest eigenvalue\n",
                "def power_iteration(A, num_iterations=100):\n",
                "    \"\"\"Find largest eigenvalue using power iteration.\"\"\"\n",
                "    n = A.shape[0]\n",
                "    v = np.random.randn(n)\n",
                "    v = v / np.linalg.norm(v)\n",
                "    \n",
                "    for _ in range(num_iterations):\n",
                "        Av = A @ v\n",
                "        v = Av / np.linalg.norm(Av)\n",
                "    \n",
                "    eigenvalue = v.T @ A @ v\n",
                "    return eigenvalue, v\n",
                "\n",
                "A = np.array([[4, 2], [2, 3]])\n",
                "val, vec = power_iteration(A)\n",
                "true_vals = np.linalg.eigvals(A)\n",
                "\n",
                "print(f\"Power iteration eigenvalue: {val:.4f}\")\n",
                "print(f\"True largest eigenvalue: {max(true_vals):.4f}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Exercise 4: Solve linear system using LU decomposition\n",
                "from scipy.linalg import lu\n",
                "\n",
                "A = np.array([[2, 1, 1], [4, 3, 3], [8, 7, 9]])\n",
                "b = np.array([1, 2, 3])\n",
                "\n",
                "P, L, U = lu(A)\n",
                "print(f\"L (lower triangular):\\n{L}\\n\")\n",
                "print(f\"U (upper triangular):\\n{U}\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "name": "python",
            "version": "3.10.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}